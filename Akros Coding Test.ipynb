{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-YapmwvVIRc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The following is the Test for the position at the **Investment Division** of Akros Technologies. \n",
    "\n",
    "\\\\\n",
    "\n",
    "Please follow carefully the instructions given below:\n",
    "\n",
    "\\\\\n",
    "\n",
    "Please note that the following ipynb file is compatible with google colab.\n",
    "\n",
    "\\\\\n",
    "\n",
    "\n",
    "The applicant should choose answer all questions  **Question 1**, **Question 2**, and **Question 3**. The topics and the distribution of the marks are as follows:\n",
    "\n",
    "*   Question 1 Python & Relevant packages: **20 marks**\n",
    "*   Question 2: Quantitative Strategy & Backtesting: **40 marks**\n",
    "*   Question 3: Reinforcement Learning: **40 marks**\n",
    "\n",
    "\n",
    "\\\\\n",
    "\n",
    "Candidates should pay attention to the **input and the output type** of the \n",
    "given sample functions. Whilst *written sample answers* serve as a guideline,  Candidates should **feel free** to write written answers in whichever form that best suits them. \n",
    "\n",
    "\\\\\n",
    "\n",
    "Please note that additional marks will be given based on the clarity of the codes, appropriate comments explaining the codes, as well as the computational efficiency of the written code.\n",
    "\n",
    "\n",
    "\\\\\n",
    "If the candidate wishes, the candidate may submit additional PDF file explaining the thought process & answer to each individual question\n",
    "\n",
    "\\\\\n",
    "All the data required to solve the problems are available [here](https://drive.google.com/drive/folders/1Cfvp9VIVnxNaaLbDusBAK0xRV3vCufOl?usp=sharing).\n",
    "\n",
    "\\\\\n",
    "**Please submit your ipynb file under the filename \"Akros Coding Test [Your Name].ipynb\" to investment-division-hr@akrostec.com along with any additional files**.\n",
    "Please contact investment-division-hr@akrostec.com should there be any problems in solving the questions. \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5A-C_oDzTJh"
   },
   "source": [
    "Please add all the python packages that you have used to solve the questions below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (0.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (from gym) (1.21.5)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "# Package downloading space\n",
    "import sys\n",
    "!{sys.executable} -m pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Users/syunie/opt/anaconda3/lib/python3.9/site-packages (2.1.2)\n",
      "ERROR: unknown command \"stable_baselines3\"\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1646965313149,
     "user": {
      "displayName": "Jin Chung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01858781054545675628"
     },
     "user_tz": -540
    },
    "id": "HP4I7SEo3iHo",
    "outputId": "59c08f31-cd88-460b-bafa-860c5e32ad10"
   },
   "outputs": [],
   "source": [
    "# Python packages to use\n",
    "from sklearn import datasets, preprocessing\n",
    "from gym.envs.toy_text.taxi import TaxiEnv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyd1y8jlv4BV"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 1: [Total 20 marks] \\\\\n",
    "Question 1A: Python \\\\\n",
    "Please answer the following questions considering both the simplicity of the code, as well as the computation time: \\\\\n",
    "i) Of the integers ranging from min_number to max_number, how many are NOT multiples of 2, 3, and 5? [3 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sxEYHxd01kFr"
   },
   "outputs": [],
   "source": [
    "def find_non_multiples(min_number: int = 1, max_number: int = 6000) -> list:\n",
    "  # Please write your answer to Question 1A part i) here\n",
    "    \n",
    "    list_of_non_multiples=[] #initiate list\n",
    "    for i in range(min_number,max_number+1): #added 1 because range function produces a integer list of [min,max)\n",
    "        if i % 2  == 0 | i % 3 == 0 | i % 5 == 0: pass #if modulo 5 is 0, get the next number\n",
    "        else: list_of_non_multiples.append(i) \n",
    "            #if the number didn't go into any previous if statements, append it to the list\n",
    "    \n",
    "    return list_of_non_multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1A(i):  5800\n",
      "This function took 0.002164125442504883 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Answer 1A(i): \",len(find_non_multiples(1,6000))) #Returning length as the question asks how many\n",
    "print(\"This function took\",time.time() - start_time,\"ms\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVWu5S2h1kOj"
   },
   "source": [
    "**ii) Find the list of all prime numbers greater than or equal to the given minimum number and less than or equal to the maximum number [5 marks]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TGeo9e-IjVSD"
   },
   "outputs": [],
   "source": [
    "def find_list_of_prime_numbers(min_number: int = 1,max_number: int = 6000) -> list:\n",
    "    # Please write your answer to Question 1A part ii) here\n",
    "    #I used Sieve of Eratosthenes here\n",
    "\n",
    "    n=2 #repersents cursor. We need to start from 2 because 1 is divisible for all numbers and it's not a prime\n",
    "    \n",
    "    list_of_prime_numbers=[] #initiate return list\n",
    "    bool_list= [True for i in range(max_number+1)] #Matrix to be sieved\n",
    "    \n",
    "    while (n<=max_number):\n",
    "        \n",
    "        if bool_list[n] == True:\n",
    "            list_of_prime_numbers.append(n) #append the new prime detected\n",
    "            for i in range(n*n,max_number+1,n): #used n*n because we already know that n is a prime\n",
    "                bool_list[i]=False\n",
    "                \n",
    "        n += 1\n",
    "    \n",
    "  \n",
    "    return list_of_prime_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_of_prime_numbers(min_number: int = 1,max_number: int = 6000) -> list:\n",
    "    # Please write your answer to Question 1A part ii) here\n",
    "    #I used Sieve of Eratosthenes here\n",
    "\n",
    "    n=2 #repersents cursor. We need to start from 2 because 1 is divisible for all numbers and it's not a prime\n",
    "    \n",
    "    list_of_prime_numbers=[] #initiate return list\n",
    "    bool_list= [True for i in range(max_number+1)] #Matrix to be sieved\n",
    "    \n",
    "    while (n<=max_number):\n",
    "        \n",
    "        if bool_list[n] == True:\n",
    "            \n",
    "            for i in range(n*n,max_number+1,n): #used n*n because we already know that n is a prime\n",
    "                bool_list[i]=False\n",
    "                \n",
    "            if n>=min_number:\n",
    "                list_of_prime_numbers.append(n) #append the new prime detected if it's bigger than the min required\n",
    "        n += 1\n",
    "    \n",
    "  \n",
    "    return list_of_prime_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1A(ii):  [101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, 547, 557, 563, 569, 571, 577, 587, 593, 599, 601, 607, 613, 617, 619, 631, 641, 643, 647, 653, 659, 661, 673, 677, 683, 691, 701, 709, 719, 727, 733, 739, 743, 751, 757, 761, 769, 773, 787, 797, 809, 811, 821, 823, 827, 829, 839, 853, 857, 859, 863, 877, 881, 883, 887, 907, 911, 919, 929, 937, 941, 947, 953, 967, 971, 977, 983, 991, 997, 1009, 1013, 1019, 1021, 1031, 1033, 1039, 1049, 1051, 1061, 1063, 1069, 1087, 1091, 1093, 1097, 1103, 1109, 1117, 1123, 1129, 1151, 1153, 1163, 1171, 1181, 1187, 1193, 1201, 1213, 1217, 1223, 1229, 1231, 1237, 1249, 1259, 1277, 1279, 1283, 1289, 1291, 1297, 1301, 1303, 1307, 1319, 1321, 1327, 1361, 1367, 1373, 1381, 1399, 1409, 1423, 1427, 1429, 1433, 1439, 1447, 1451, 1453, 1459, 1471, 1481, 1483, 1487, 1489, 1493, 1499, 1511, 1523, 1531, 1543, 1549, 1553, 1559, 1567, 1571, 1579, 1583, 1597, 1601, 1607, 1609, 1613, 1619, 1621, 1627, 1637, 1657, 1663, 1667, 1669, 1693, 1697, 1699, 1709, 1721, 1723, 1733, 1741, 1747, 1753, 1759, 1777, 1783, 1787, 1789, 1801, 1811, 1823, 1831, 1847, 1861, 1867, 1871, 1873, 1877, 1879, 1889, 1901, 1907, 1913, 1931, 1933, 1949, 1951, 1973, 1979, 1987, 1993, 1997, 1999, 2003, 2011, 2017, 2027, 2029, 2039, 2053, 2063, 2069, 2081, 2083, 2087, 2089, 2099, 2111, 2113, 2129, 2131, 2137, 2141, 2143, 2153, 2161, 2179, 2203, 2207, 2213, 2221, 2237, 2239, 2243, 2251, 2267, 2269, 2273, 2281, 2287, 2293, 2297, 2309, 2311, 2333, 2339, 2341, 2347, 2351, 2357, 2371, 2377, 2381, 2383, 2389, 2393, 2399, 2411, 2417, 2423, 2437, 2441, 2447, 2459, 2467, 2473, 2477, 2503, 2521, 2531, 2539, 2543, 2549, 2551, 2557, 2579, 2591, 2593, 2609, 2617, 2621, 2633, 2647, 2657, 2659, 2663, 2671, 2677, 2683, 2687, 2689, 2693, 2699, 2707, 2711, 2713, 2719, 2729, 2731, 2741, 2749, 2753, 2767, 2777, 2789, 2791, 2797, 2801, 2803, 2819, 2833, 2837, 2843, 2851, 2857, 2861, 2879, 2887, 2897, 2903, 2909, 2917, 2927, 2939, 2953, 2957, 2963, 2969, 2971, 2999, 3001, 3011, 3019, 3023, 3037, 3041, 3049, 3061, 3067, 3079, 3083, 3089, 3109, 3119, 3121, 3137, 3163, 3167, 3169, 3181, 3187, 3191, 3203, 3209, 3217, 3221, 3229, 3251, 3253, 3257, 3259, 3271, 3299, 3301, 3307, 3313, 3319, 3323, 3329, 3331, 3343, 3347, 3359, 3361, 3371, 3373, 3389, 3391, 3407, 3413, 3433, 3449, 3457, 3461, 3463, 3467, 3469, 3491, 3499, 3511, 3517, 3527, 3529, 3533, 3539, 3541, 3547, 3557, 3559, 3571, 3581, 3583, 3593, 3607, 3613, 3617, 3623, 3631, 3637, 3643, 3659, 3671, 3673, 3677, 3691, 3697, 3701, 3709, 3719, 3727, 3733, 3739, 3761, 3767, 3769, 3779, 3793, 3797, 3803, 3821, 3823, 3833, 3847, 3851, 3853, 3863, 3877, 3881, 3889, 3907, 3911, 3917, 3919, 3923, 3929, 3931, 3943, 3947, 3967, 3989, 4001, 4003, 4007, 4013, 4019, 4021, 4027, 4049, 4051, 4057, 4073, 4079, 4091, 4093, 4099, 4111, 4127, 4129, 4133, 4139, 4153, 4157, 4159, 4177, 4201, 4211, 4217, 4219, 4229, 4231, 4241, 4243, 4253, 4259, 4261, 4271, 4273, 4283, 4289, 4297, 4327, 4337, 4339, 4349, 4357, 4363, 4373, 4391, 4397, 4409, 4421, 4423, 4441, 4447, 4451, 4457, 4463, 4481, 4483, 4493, 4507, 4513, 4517, 4519, 4523, 4547, 4549, 4561, 4567, 4583, 4591, 4597, 4603, 4621, 4637, 4639, 4643, 4649, 4651, 4657, 4663, 4673, 4679, 4691, 4703, 4721, 4723, 4729, 4733, 4751, 4759, 4783, 4787, 4789, 4793, 4799, 4801, 4813, 4817, 4831, 4861, 4871, 4877, 4889, 4903, 4909, 4919, 4931, 4933, 4937, 4943, 4951, 4957, 4967, 4969, 4973, 4987, 4993, 4999, 5003, 5009, 5011, 5021, 5023, 5039, 5051, 5059, 5077, 5081, 5087, 5099, 5101, 5107, 5113, 5119, 5147, 5153, 5167, 5171, 5179, 5189, 5197, 5209, 5227, 5231, 5233, 5237, 5261, 5273, 5279, 5281, 5297, 5303, 5309, 5323, 5333, 5347, 5351, 5381, 5387, 5393, 5399, 5407, 5413, 5417, 5419, 5431, 5437, 5441, 5443, 5449, 5471, 5477, 5479, 5483, 5501, 5503, 5507, 5519, 5521, 5527, 5531, 5557, 5563, 5569, 5573, 5581, 5591, 5623, 5639, 5641, 5647, 5651, 5653, 5657, 5659, 5669, 5683, 5689, 5693, 5701, 5711, 5717, 5737, 5741, 5743, 5749, 5779, 5783, 5791, 5801, 5807, 5813, 5821, 5827, 5839, 5843, 5849, 5851, 5857, 5861, 5867, 5869, 5879, 5881, 5897, 5903, 5923, 5927, 5939, 5953, 5981, 5987]\n",
      "\n",
      "This function took 0.0027408599853515625 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Answer 1A(ii): \",find_list_of_prime_numbers(100,6000)) \n",
    "#Returning list as the question asks to return the list\n",
    "#Note that 1 is not a prime number so we are not including 1 in the result.\n",
    "print(\"\\nThis function took\",time.time() - start_time,\"ms\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phTy-sVoh6FU"
   },
   "source": [
    "**Question 1B: Numpy \\\\\n",
    "Please use the numpy package to answer the following questions: \\\\\n",
    "Given that numpy arrays a, b, and c are:**\n",
    "\n",
    "\n",
    "```\n",
    "a = np.array([1,2,3,2,3,4,3,4,5,6], [7,2,10,2,7,4,9,4,9,8], [3,2,1,4,6,4,3,4,0,2])\n",
    "b = np.array([1,2,3,2,3,4,3,4,5,6], [7,2,10,2,7,4,9,4,9,8], [3,2,1,4,6,4,3,4,0,2])\n",
    "c = np.array([1,2,3,2,3,4,3,4,5,7], [7,2,10,2,7,4,9,4,9,9], [3,2,1,4,6,4,3,4,0,3])\n",
    "```\n",
    "\n",
    "**i) How do you vertically stack b and c onto a to give d? [1 mark]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f_bVb-Hhl999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  2,  3,  4,  3,  4,  5,  6],\n",
       "       [ 7,  2, 10,  2,  7,  4,  9,  4,  9,  8],\n",
       "       [ 3,  2,  1,  4,  6,  4,  3,  4,  0,  2],\n",
       "       [ 1,  2,  3,  2,  3,  4,  3,  4,  5,  7],\n",
       "       [ 7,  2, 10,  2,  7,  4,  9,  4,  9,  9],\n",
       "       [ 3,  2,  1,  4,  6,  4,  3,  4,  0,  3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def np_stack(a: np.array, b: np.array, c: np.array) -> np.array:\n",
    "  # Please write your answer to Question 1B part i) here\n",
    "    d=np.concatenate((b, c)) #it does the same work as vertical stacking\n",
    "    return d\n",
    "    \n",
    "\n",
    "#The given code to make a, b, and c was making TypeError so I added outer brackets assuming it was a mistake\n",
    "\n",
    "a = np.array([ [1,2,3,2,3,4,3,4,5,6], [7,2,10,2,7,4,9,4,9,8], [3,2,1,4,6,4,3,4,0,2] ])\n",
    "b = np.array([ [1,2,3,2,3,4,3,4,5,6], [7,2,10,2,7,4,9,4,9,8], [3,2,1,4,6,4,3,4,0,2] ])\n",
    "c = np.array([ [1,2,3,2,3,4,3,4,5,7], [7,2,10,2,7,4,9,4,9,9], [3,2,1,4,6,4,3,4,0,3] ])\n",
    "\n",
    "np_stack(a,b,c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5C8uV1d1WK0"
   },
   "source": [
    "**ii) Given b, replace all numbers greater than 3 and less than 8 by np.nan to give e [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5BY9XLBr1Xx1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  2.  3. nan  3. nan nan nan]\n",
      " [nan  2. 10.  2. nan nan  9. nan  9.  8.]\n",
      " [ 3.  2.  1. nan nan nan  3. nan  0.  2.]]\n"
     ]
    }
   ],
   "source": [
    "def fast_convert_to_nan(arr: np.array, min_number: int = 3, max_number: int = 8) -> np.array:\n",
    "  # Please write your answer to Question 1B part ii) here\n",
    "    arr=arr.astype('float')\n",
    "    arr[(arr > min_number) & (arr < max_number)] = np.nan\n",
    "    return arr\n",
    "e=fast_convert_to_nan(b,3,8)\n",
    "print(e)\n",
    "#I had to make e as a float array because np.array only takes one dtype and nan is a float type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9cHPDtc1YHs"
   },
   "source": [
    "**iii) Using your answer to 1B part ii), find the row-wise mean, median and standard deviation of e [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "W6OsB5qK1YSL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.33333333, 6.66666667, 1.83333333]),\n",
       " array([2.5, 8.5, 2. ]),\n",
       " array([0.74535599, 3.34995854, 1.06718737]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mean_median_sd(arr: np.array) -> np.array:\n",
    "  # Please write your answer to Question 1B part iii) here\n",
    "    mean=np.nanmean(arr,axis=1)\n",
    "    median=np.nanmedian(arr,axis=1)\n",
    "    sd=np.nanstd(arr,axis=1)\n",
    "    return mean, median, sd\n",
    "get_mean_median_sd(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdOCOzvYn1SL"
   },
   "source": [
    "**Question 1C: Pandas\n",
    "Please use the pandas package to answer the following questions: \\\\\n",
    "i) Using sklearn's datasets package, load the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) and convert the dataset to pandas dataframe with following column names and the corresponding data: Sepal Length, Sepal Width, Petal Length, Petal Width, and Target (classification label). [1 mark]** \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6tSg2aFa0bpv"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jKSlgVYt0ITk"
   },
   "outputs": [],
   "source": [
    "# Please write your answer to Question 1C part i) here\n",
    "iris_df=pd.DataFrame(iris.data.T,index=['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']).T\n",
    "iris_df['Target']=iris.target #Target was not in the data so I had to manually find and append it to the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PqG6T4V0w4-"
   },
   "source": [
    "**ii) Calculate the column-wise rank of the dataframe. Then normalize the dataset column-wise using the normalization method of your choice. Take care not to normalize the Target(classification label) [3 marks]** \\\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(iris_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "  # Please write your answer to Question 1C part ii) here\n",
    "\n",
    "    df=iris_df.rank(axis=0) #rank each Series in the iris_df\n",
    "    normalized_iris_df=pd.DataFrame(preprocessing.normalize(iris_df[['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']].T),\n",
    "                                   index= ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']).T\n",
    "    #preprocessing gives list of list in an incompatible direction (gives list of rows) so we had to Transpose it twice\n",
    "    #to make it in a form that I can make DataFrame out of it\n",
    "    \n",
    "    normalized_iris_df['Target']=iris_df['Target']\n",
    "    #I am not supposed to normalize Target as it makes the value more confusing.\n",
    "    #seems like Target is not a measurement but a classification symbol for 0,1,2\n",
    "    \n",
    "    return normalized_iris_df\n",
    "\n",
    "normalized_iris_df=normalize_dataframe(iris_df)\n",
    "\n",
    "#maybe this is expensive\n",
    "#no need to print them as it's the variable for the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTI4iwph02hE"
   },
   "source": [
    "**iii) Group the normalized dataframe by classification label from smallest to largest (i.e 0 to 2). In each classification group, sort and print the normalized dataframe from the largest to the smallest sepal length. [3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EXJzSF-H03Am"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sepal_Length Sepal_Width Petal_Length Petal_Width Target\n",
      "41             9           9            4           2      0\n",
      "28             8           9            3           1      0\n",
      "1              8           9            3           1      0\n",
      "25             8           9            3           1      0\n",
      "23             8           9            3           3      0\n",
      "..           ...         ...          ...         ...    ...\n",
      "80             0           0            0           0      9\n",
      "79             0           0            0           0      9\n",
      "78             0           0            0           0      9\n",
      "77             0           0            0           0      9\n",
      "149            0           0            0           0      9\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal_Length Sepal_Width Petal_Length Petal_Width Target\n",
       "0              7           9            2           1      0\n",
       "1              8           9            3           1      0\n",
       "2              7           9            3           1      0\n",
       "3              7           9            3           1      0\n",
       "4              7           9            2           1      0\n",
       "..           ...         ...          ...         ...    ...\n",
       "145            0           0            0           0      9\n",
       "146            0           0            0           0      9\n",
       "147            0           0            0           0      9\n",
       "148            0           0            0           0      9\n",
       "149            0           0            0           0      9\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_and_print_dataframe(normalized_iris_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "  # Please write your answer to Question 1C part iii) here\n",
    "\n",
    "    sorted_iris_df=normalized_iris_df.apply(lambda x: pd.cut(x,bins=10,labels=list(range(0,10))), axis=1)\n",
    "    #classification label of 0,1,2 was to vague to give any specific information, so I made it to be 10 bins\n",
    "    \n",
    "    print(sorted_iris_df.sort_values(by=['Sepal_Length'],ascending=False))\n",
    "    #print out the sorted value\n",
    "    #Desceding sorting\n",
    "    \n",
    "    return sorted_iris_df\n",
    "\n",
    "sort_and_print_dataframe(normalized_iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe6y6MXT00PZ"
   },
   "source": [
    "---\n",
    "**Question 2 [Total 40 marks] \\\\\n",
    "Question 2 requires the use of the data in the following [link](https://drive.google.com/drive/folders/1Cfvp9VIVnxNaaLbDusBAK0xRV3vCufOl) \\\\\n",
    "Please note that there are no definite answers to the questions --> Use logical reasoning to provide answer to the given questions**\n",
    "\n",
    "\\\\\n",
    "**Question 2A: Single Factor Portfolio \\\\\n",
    "Data to use: f1.csv, total_return.csv, market_value.csv \\\\\n",
    "i) f1.csv is a single factor that we look at in order to decide the companies that we should invest in. Preprocess the data using the method of your choice, taking consideration of NAN values. Formulate each of the portfolio weight defined as below. Plot the performance of each portfolio by using the total_return.csv [6 marks]**:\n",
    "*   **Top 50 Equal Weight Portfolio**\n",
    "*   **Top 50 Market Weight Portfolio**\n",
    "*   **Top 25% Long Equal-Weighted Portfolio & Top 25% Short Equal-Weighted Portfolio** (Use long leverage ratio of 1.5 and short leverage ratio of 0.5. Note that Long and Short Weights should both sum to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EWH4aGO206Ni"
   },
   "outputs": [],
   "source": [
    "# Load your data  to use for Question 2\n",
    "\n",
    "# Get CSV files list from a folder\n",
    "fpath = '/Users/syunie/Documents/python/akrosdata/factors' #f stands for factors\n",
    "mpath = '/Users/syunie/Documents/python/akrosdata/market' #m stands for market\n",
    "\n",
    "#get for all csv files\n",
    "ffiles = glob.glob(fpath + \"/*.csv\")\n",
    "mfiles = glob.glob(mpath + \"/*.csv\")\n",
    "\n",
    "#get a list of file names\n",
    "fnames=[]\n",
    "for path in ffiles:\n",
    "    fnames.append(re.search('([^\\/]+$)',path).group())\n",
    "    \n",
    "mnames=[] \n",
    "for path in mfiles:\n",
    "    mnames.append(re.search('([^\\/]+$)',path).group())\n",
    "\n",
    "# Read each csv file into DataFrame in a form of generator for efficiency\n",
    "flist = (pd.read_csv(file,parse_dates=['date'],index_col='date') for file in ffiles)\n",
    "mlist = (pd.read_csv(file,parse_dates=['date'],index_col='date') for file in mfiles)\n",
    "\n",
    "#make dictionaries of DataFrames\n",
    "fdict = {fnames[i]: next(flist) for i in range(len(fnames))}\n",
    "mdict = {mnames[i]: next(mlist) for i in range(len(mnames))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the necessary data for 2A specifically\n",
    "f1=fdict['f_1.csv']\n",
    "tot=mdict['total_return.csv']\n",
    "val=mdict['market_value.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not too much of an expert in economics or investing but I did some google search to understand the question. \n",
    "\n",
    "I assume f-nn files are undefined (someone did it for me and maybe I can figure it out later) \"factors\" that effects the value of each asset (columns). NaN values mean that company doesn't exist yet or closed for sales.\n",
    "\n",
    "I learned that equal weight means that we are simply dividing the budget and equally for all stocks no matter how promising they are. I assume we have new budget of 1 for each month for simplicity. I first thought it doesn't make sense to actually do this but seems like it's a pretty promising technique than I expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fazuF178Nh3"
   },
   "outputs": [],
   "source": [
    "#Staratgy of evenly invest on all stocks\n",
    "def get_equal_weight_portfolio(f1: pd.DataFrame, top_n: int = 50) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part i) here\n",
    "    #see how those assets are changing over time\n",
    "    ret=f1.pct_change() #percent change of factors each month\n",
    "    \n",
    "    #pct change from 0 to a number was making infinity so replace them for better calculation\n",
    "    ret=ret.replace(-1*float('inf'), np.NaN)\n",
    "    ret=ret.replace(float('inf'), np.NaN)\n",
    "\n",
    "    #I made weighted average to be 1/existing assets of that time\n",
    "    num_exist= f1.count(axis=1) # number of exsisting stocks for each time\n",
    "    weight = 1/num_exist\n",
    "    \n",
    "    #total return of hypothesized investment\n",
    "    retmul=ret.mul(weight,axis=0)\n",
    "    retdot=retmul.sum(skipna=True, axis=0)\n",
    "    \n",
    "    #Volatility of each case\n",
    "    retvol=retmul.std(skipna=True, axis=0)**2\n",
    "    \n",
    "    #put them in a df\n",
    "    ew_portfolio_all=pd.DataFrame(retdot,columns=['EWP'])\n",
    "    ew_portfolio_all['Volatility']=retvol\n",
    "    \n",
    "    #get top 50s\n",
    "    ew_portfolio=ew_portfolio_all.sort_values(by=['EWP'],ascending=False).head(top_n)\n",
    "    return ew_portfolio\n",
    "\n",
    "ew_portfolio=get_equal_weight_portfolio(f1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7czatYx8gCP"
   },
   "outputs": [],
   "source": [
    "#Strategy of invest more on expensive ones, less on cheap ones\n",
    "def get_market_weight_portfolio(f1: pd.DataFrame, top_n: int = 50) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part i) here\n",
    "    #see how those assets are changing over time\n",
    "    ret=f1.pct_change() #monthly stock returns\n",
    "    \n",
    "    #pct change from 0 to a number was making infinity so replace them for better calculation\n",
    "    ret=ret.replace(-1*float('inf'), np.NaN)\n",
    "    ret=ret.replace(float('inf'), np.NaN)\n",
    "    \n",
    "    #For market value based weight\n",
    "    #Find matching assets since I belive column names are ID for each asset\n",
    "    marketdf=val[list(f1.columns)]\n",
    "    weight=marketdf.div(marketdf.sum(axis=1), axis=0) #row percentage of each item\n",
    "\n",
    "    #How much we should've made if we invested accordingly at the end of the month?\n",
    "    retmul=ret.mul(weight,axis=0)\n",
    "    retdot=retmul.sum(skipna=True, axis=0)\n",
    "    \n",
    "    #Volatility of each case\n",
    "    retvol=retmul.std(skipna=True, axis=0)**2\n",
    "    \n",
    "    #put them in a df\n",
    "    mw_portfolio_all=pd.DataFrame(retdot,columns=['MWP'])\n",
    "    mw_portfolio_all['Volatility']=retvol\n",
    "    \n",
    "    #get top 50s\n",
    "    mw_portfolio=mw_portfolio_all.sort_values(by=['MWP'],ascending=False).head(top_n)\n",
    "    \n",
    "    #calculate market_weight\n",
    "    return mw_portfolio\n",
    "\n",
    "mw_portfolio=get_market_weight_portfolio(f1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot['001020_02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYV0_WYa8gQf"
   },
   "outputs": [],
   "source": [
    "#Top 25% Long Equal-Weighted Portfolio & Top 25% Short Equal-Weighted Portfolio \n",
    "#Use long leverage ratio of 1.5 and short leverage ratio of 0.5. \n",
    "#Note that Long and Short Weights should both sum to 1\n",
    "def get_long_short_portfolio(f1: pd.DataFrame, percentile: float = 0.25, long_ratio: float = 1.5, short_ratio: float = 0.5) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part i) here\n",
    "    \n",
    "    return ls_portfolio\n",
    "\n",
    "ls_portfolio = get_long_short_portfolio(f1,0.25,1.5,0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_f1_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Staratgy of evenly invest on all stocks\n",
    "def get_real_chage_from_total(factor: pd.DataFrame, compared_portfolio: pd.DataFrame, total_return: pd.DataFrame, option: str) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part i) here\n",
    "    \n",
    "    #seive out only the necessary parts\n",
    "    ew_assetlist=compared_portfolio.index\n",
    "    ret=tot[ew_assetlist]\n",
    "    \n",
    "    if option =='ew':\n",
    "        #I made weighted average to be 1/existing assets of that time\n",
    "        num_exist= total_return.count(axis=1) # number of exsisting stocks for each time\n",
    "        print(num_exist)\n",
    "        weight = 1/num_exist\n",
    "    elif option == 'mw':\n",
    "        #For market value based weight\n",
    "        #Find matching assets since I belive column names are ID for each asset\n",
    "        marketdf=val[list(f1.columns)]\n",
    "        weight=marketdf.div(marketdf.sum(axis=1), axis=0) #row percentage of each item\n",
    "\n",
    "    #total return of hypothesized investment\n",
    "    retmul=ret.mul(weight,axis=0)\n",
    "    retdot=retmul.sum(skipna=True, axis=0)\n",
    "    \n",
    "    #Volatility of each case\n",
    "    retvol=retmul.std(skipna=True, axis=0)**2\n",
    "    ew_portfolio_all=pd.DataFrame()\n",
    "    ew_portfolio_all['Weighted Price']=retdot\n",
    "    #put them in a df\n",
    "\n",
    "    ew_portfolio_all['Volatility']=retvol\n",
    "    \n",
    "    #get top 50s\n",
    "    ew_portfolio=ew_portfolio_all.sort_values(by='Weighted Price',ascending=False)\n",
    "    return ew_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_real_chage_from_total(ew_f1_real,'ew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prerprocessing of total return csv for the plotting next\n",
    "ew_assetlist=ew_portfolio.index\n",
    "ew_f1_real=tot[ew_assetlist]\n",
    "ew_f1_real2=get_real_chage_from_total(ew_f1_real,'ew')\n",
    "print(ew_f1_real2,'\\n\\n',ew_portfolio)\n",
    "ew_portfolio['EWP'].sub(ew_f1_real2['Weighted Price'], fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWWNcQgI0xDG"
   },
   "outputs": [],
   "source": [
    "# plot the performance of equal_weight_portfolio, market_weight_portfolio, and long_short_weight_portfolio\n",
    "plt.errorbar(ew_f1_real2['Weighted Price'],c='r')\n",
    "plt.plot(ew_portfolio.EWP,c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tot['149337_01'].sum())\n",
    "print(ew_portfolio.loc['149337_01'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr0kWPDH8Lj3"
   },
   "source": [
    "**Data to use: f1.csv, total_return.csv, market_value.csv, benchmark_return.csv \\\\\n",
    "ii) How can you measure the performance of the f1 portfolios that we have implemented in 2A part i) against the benchmark return? Please select and calculate multiple metrics of your choice to assess the performance of each individual portfolio. Of the 3 portfolios, which portfolio performs the best and why? [4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the necessary data for 2B specifically\n",
    "bench=mdict['benchmark_return.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smxHbThd-CTs"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(portfolio: pd.DataFrame, total_return: pd.DataFrame, benchmark_return: pd.DataFrame) -> dict:\n",
    "  # Please write your answer to Question 2A part ii) here\n",
    "  return {'metrics_1': metrics_1, 'metrics_2': metrics_2, 'metrics_3': metrics_3, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPo8sP_B1Ifm"
   },
   "outputs": [],
   "source": [
    "# Metrics of the 3 portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_YfTuKgjLn6"
   },
   "source": [
    "(Your answer to Question 2A part ii))\n",
    "\n",
    "\n",
    "> The best performing portfolio is ... because ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlJJy3ePQ3t8"
   },
   "source": [
    "**Data to use: macro.csv \\\\\n",
    "iii) macro.csv file provides a number of macroeconomic factors that our portfolio are exposed to. Pre-process the macroeconomic factors using methods of your choice. How and why have you decided to use such methods? [5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ze_7PDpQ62L"
   },
   "outputs": [],
   "source": [
    "def preprocess_macro_data(macro: pd.DataFrame) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part iii) here\n",
    "  return preprocessed_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVIpTkjKSZBV"
   },
   "source": [
    "(Your answer to Question 2A part iii))\n",
    "\n",
    "\n",
    "> I have preprocessed each macroeconomic factor by ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meZkksnB_gcj"
   },
   "source": [
    "**Data to use: your answers to 2A part i) and iii) \\\\\n",
    "iv) Using the preprocessed macro data from your answer to 2A part iii) as well as your answers to 2A part i), define and calculate the risk exposure of the Top 50 Equal Weight Portfolio Return from f1 to each macroeconomic factor. [4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG110JkFAbWt"
   },
   "outputs": [],
   "source": [
    "def calculate_macroeconomic_exposure(f1_ew_return: pd.DataFrame, preprocessed_macro: pd.DataFrame) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2A part iv) here\n",
    "  return macroeconomic_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1u3CMNjq1hqx"
   },
   "outputs": [],
   "source": [
    "# Macroeconomic Exposure of Top 50 Equal Weight Portfolio Return from f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J3XMNaZ2cPN"
   },
   "source": [
    "(Your answer to Question 2A part iv))\n",
    "\n",
    "\n",
    "> I have defined the risk exposure of the portfolio to each macroeconomic factor by ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEd5qI1XDV-I"
   },
   "source": [
    "**Question 2B: Multi Factor Portfolio \\\\\n",
    "Data to use: f1 - f5.csv, total_return.csv, (your answer to 2A part iii) \\\\\n",
    "i) Using multiple factors f1 - f5 and allocating appropriate weight to each factor by using optimization, *or by any other means of your choice using f1- f5*, formulate a risk-minimizing factor f6. [5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B31BRXGhFM7X"
   },
   "outputs": [],
   "source": [
    "def get_f6(f1: pd.DataFrame, f2: pd.DataFrame, f3: pd.DataFrame, f4: pd.DataFrame, f5: pd.DataFrame, total_return: pd.DataFrame, preprocessed_macro: pd.DataFrame) -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2B part i) here\n",
    "  return f6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzXWzRMfFLfC"
   },
   "source": [
    "**Data to use: f1 - f5.csv, total_return.csv, benchmark_return.csv \\\\\n",
    "ii) Using your answers to question 2A or otherwise, extract Top 50 Equal Weight Portfolio and evaluate the performance metrics & macroeconomic risk exposure of each factor from f1 to f6. Compare the results of f1-f5 and f6 and explain in words the difference between the result of f1 to f5 and f6. [4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKYKyI4c15-f"
   },
   "outputs": [],
   "source": [
    "# f1 - f6 portfolio return calculation, risk exposure calculation, metrics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0qwxq4cGZ0p"
   },
   "source": [
    "(Your answer to Question 2B part ii))\n",
    "\n",
    "\n",
    "> The differences between the result of f1 to f5 and f6 are ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji_OTTStG88q"
   },
   "source": [
    "**Question 2C: Multi Factor Allocation \\\\\n",
    "The ultimate goal of this question is to extract Top 50 Equal Weight Portfolio given 100 factors (f1.csv - f100.csv). \\\\\n",
    "Data to use: f1 - f100.csv, macro.csv, total_return.csv \\\\\n",
    "i) Using your answer to Question 2A part ii) or otherwise, write a function that selects 20 factors out of the given 100 factors. How have you decided to choose these 20 factors and why? Is there a way to make the process quicker by using multiprocessing? [4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7uwfAoW3I3s"
   },
   "outputs": [],
   "source": [
    "def get_selected_factors() -> list:\n",
    "  # Please write your answer to Question 2C part i) here\n",
    "  return selected_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0lQkGKhPraA"
   },
   "source": [
    "**Your selected factors:** \\\\\n",
    "(Your answer to Question 2C part i)) \\\\\n",
    "> f1, f2, f3,... \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKQG8VutQf-_"
   },
   "source": [
    "(Your answer to Question 2C part i))\n",
    "\n",
    "\n",
    "> I have decided to select the 20 factors using ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygZnkrkcRGdC"
   },
   "source": [
    "**Data to use: f1 - f100.csv (20 selected from the previous question), total_return.csv, macro.csv, benchmark_return.csv \\\\\n",
    "ii) By calculating the combined factor *f_combined* using the selected 20 factors, plot the performance of the Top 50 Equal Weight Portfolio. Compare the performance of the combined factor Top 50 Equal Weight Portfolio to any single factor Top 50 Equal Weight Portfolio [5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsow-O7KRz6W"
   },
   "outputs": [],
   "source": [
    "def get_f_combined() -> pd.DataFrame:\n",
    "  # Please write your answer to Question 2C part ii) here\n",
    "  return f_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MAVRAb23lFg"
   },
   "outputs": [],
   "source": [
    "# f_combined portfolio return calculation, risk exposure calculation, metrics calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnFiuEisR0a-"
   },
   "source": [
    "(Your answer to Question 2C part ii))\n",
    "\n",
    "\n",
    "> The performance of the combined 20 factors ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z01sFjeLSBdo"
   },
   "source": [
    "**iii) In real-word operation, we have to select factors without any biases. What kind of biases should we try to prevent? Describe in words how we can form a combined factor and create a back-testing simulation to minimze the effect of bias. [3 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoAweVvVScq7"
   },
   "source": [
    "(Your answer to Question 2C part iii))\n",
    "\n",
    "\n",
    "> A combined factor without any look-ahead bias may be formulated by ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvHDvVKVuVDF"
   },
   "source": [
    "---\n",
    "**Question 3 [Total 40 marks] \\\\\n",
    "Question 3A: Taxi-v3 Fundamental Questions \\\\\n",
    "Using the Taxi-v3 [environment](https://gym.openai.com/envs/Taxi-v3/) given below, please answer the following questions: \\\\\n",
    "The Taxi-v3 environment can be formed using the following snippet**:\n",
    "\n",
    "\n",
    "```\n",
    "random.seed(1234)\n",
    "env = gym.make(\"Taxi-v3\").env #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "env.render()\n",
    "```\n",
    "\n",
    "\n",
    "**i)  What is the dimension of the observation space? Why is it this particular number? [3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gym.envs.toy_text.taxi import TaxiEnv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import random\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Pr1jTFGU3uMn"
   },
   "outputs": [],
   "source": [
    "# Load the Taxi-v3 environment here\n",
    "random.seed(1234)\n",
    "TaxiEnv = gym.make(\"Taxi-v3\", render_mode=\"human\") #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "#auto human rendering is currently broken. it could've been restored on the point of you checking this.\n",
    "#so check the https://github.com/openai/gym/blob/master/gym/envs/toy_text/taxi.py if necessary\n",
    "TaxiEnv.reset()\n",
    "TaxiEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IJx1JlMWZOsn"
   },
   "outputs": [],
   "source": [
    "def get_observation_dimension(env: TaxiEnv) -> int:\n",
    "  # Please write your answer to Question 3A part i) here\n",
    "    # Observation and action space \n",
    "    obs_dim = env.observation_space.n\n",
    "    return obs_dim\n",
    "obs_dim=get_observation_dimension(TaxiEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3M3ZXOyXlGB"
   },
   "source": [
    "(Your answer to Question 3A part i))\n",
    "\n",
    "\n",
    "> The dimension of the observation space is 500 because there are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is in the taxi), and 4 destination locations. *Definition from the official github documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGDmR5nBZNmz"
   },
   "source": [
    "**ii)  What is the dimension of the action space? What kind of action does each  number represent? [3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vQQJCcwtZczU"
   },
   "outputs": [],
   "source": [
    "def get_action_dim(env: TaxiEnv) -> int:\n",
    "  # Please write your answer to Question 3A part ii) here\n",
    "    action_dim = env.action_space.n\n",
    "    return action_dim\n",
    "act_dim=get_action_dim(TaxiEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDMvrY1_ZZYX"
   },
   "source": [
    "(Your answer to Question 3A part ii))\n",
    "\n",
    "\n",
    "> The dimension of the action space is 6 \\\\\n",
    "Each number represents \n",
    "    - 0: move south\n",
    "    - 1: move north\n",
    "    - 2: move east\n",
    "    - 3: move west\n",
    "    - 4: pickup passenger\n",
    "    - 5: drop off passenger\n",
    "    * also from the github documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbh1HwWT4Yjd"
   },
   "source": [
    "**iii) How are the rewards formulated for the Taxi-v3 environment? [2 marks]** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h_oArAH4jxi"
   },
   "source": [
    "(Your answer to Question 3A part iii))\n",
    "\n",
    "\n",
    "> The rewards are formulated by: \\\n",
    "    (-1) per step unless other reward is triggered.\\\n",
    "    (+20) delivering passenger.\\\n",
    "    (-10)  executing \"pickup\" and \"drop-off\" actions illegally. Illegal is a case when a passanger is picked up/dropped off in the middle of the road because the assigned max step is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZShto7Wb-Nc"
   },
   "source": [
    "**iv) Write a simple code that runs 10 number of episodes of the Taxi Environment. Each episode should last 50 number of steps and the action should be randomly sampled from the action space. Make sure to render the environment. Why are there 4 physical locations but 5 possible locations for the passenger? [5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q2SliKQtcWod"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_run(env: TaxiEnv, number_of_episodes: int = 10, number_of_steps: int = 50) -> bool :\n",
    "  # I had to change the return value of the annotation above to not specify it to True to avoid error\n",
    "  # Please write your answer to Question 3A part iv) here\n",
    "\n",
    "    for episode in range(number_of_episodes):\n",
    "        # get new episode environment\n",
    "        state= env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(number_of_steps):\n",
    "            action = env.action_space.sample() #get random action\n",
    "            new_state, reward, transition, done, info = env.step(action) #get the result of random action\n",
    "            state = new_state #update state\n",
    "\n",
    "    return True\n",
    "#It is getting rendered on the previous window I opened\n",
    "\n",
    "simple_run(TaxiEnv,10,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 locations are possible as there are 4 destination locations and one case when the passenger is in the taxi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P2bBtxy4yi_"
   },
   "source": [
    "**Question 3B: Bellman's Equation and Q-Learning in the Taxi Environment**\n",
    "**i) Explain the Bellman Expectation and Optimality equations. Elaborate how a q-function is updated  [5 marks]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdrUS7Dh4_g6"
   },
   "source": [
    "Bellman equation is a set of equation that helps us to find optimal policies and value functions based on current state/action and next sate/action. \\\n",
    "\\\n",
    "Bellman Equation has two types : Expectation and Optimality\\\n",
    "\\\n",
    "Expectation equation has two functions: State-value function V(s) and state-action value function Q(s,a) which we call q-function.\\\n",
    "*Denotation: state(s), action(a), policy(pi)\\\n",
    "\\\n",
    "V(s) function finds the value of being in a specific state as a function of immediate reward + discouted reward value of successor states. However, how do we calculate the discounted reward of next states as there are multiple next choices to take?\\\n",
    "\\\n",
    "Thankfully, we have a policy (assigned probability of choosing each action) fixed to choose the next action. Here comes Q function, also called state-action value function, that calculates how good it is for an agent to take actions in a state following policy specified. If we do weighted average of all possible q functions, we can find the value of possible next states, and if we discount it and add to the immediate reward, we can calculate V(s).\\\n",
    "\\\n",
    "This is how Bellman expectation equation works, finding the true v(s) when a policy is fixed. That policy is first given as random becuase we don't know it yet but we are going learn.\\\n",
    "\\\n",
    "However, remember that the final goal of reinforced learning is finding the policy that maximizes the return, not the value of each state. As we do bunch of Bellman Expectation Equation, we will be able to find the policy that makes the maximum return. We call the policy we found \"optimal policy\" and the Bellman Equation that follows the optimal policy is called Bellman Optimality Equation.\\\n",
    "\\\n",
    "After finding the policy, we need to update our policy (that was first randomized) because that's all about learning. And Q is the deepest function that incorporates policy. With the new policy, we can do this process again to find the next better version of optimal policy and finally the best and most optimized policy that the agent can follow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg1NgayDZnEE"
   },
   "source": [
    "**ii) Now, instead of randomly sampling action from the action space, we wish to implement Q-learning by means of formulating q-table, and sampling an action in an epsilon greedy-manner. Given the learning rate and the discount rate, implement two functions:** \n",
    "\n",
    "*   function that trains q-table for a certain number of episodes and returns q table in np.array format\n",
    "*   function that runs 10 number of episodes with the action sampled from the q-table formed by the function above\n",
    "\n",
    "**How well does Q-learning perform against the random sampling method? Explain how your code works in words [10 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "59XAfZxsHhWo"
   },
   "outputs": [],
   "source": [
    "def train(env: TaxiEnv, number_of_episodes:int = 10, number_of_steps: int = 5, learning_rate: float = 0.1, discount_rate: float = 0.6, epsilon: float = 0.3) -> np.array:\n",
    "  # Please write your answer to Question 3B part ii))\n",
    "    qtable = np.zeros((obs_dim,act_dim)) #initialize q table as zeros\n",
    "    \n",
    "    for episode in range(number_of_episodes):\n",
    "        # get new episode environment\n",
    "        state= env.reset()[0]\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(number_of_steps):\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## Get a random number\n",
    "            randn = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if randn > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, transition, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + discount_rate * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If we are dead : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            \n",
    "    return qtable\n",
    "q_table = train(TaxiEnv, 10, 5, 0.1, 0.6, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0.]\\n ...\\n [0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0.]\\n [0. 0. 0. 0. 0. 0.]]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3O0nJp9xOhUQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q_run(env: TaxiEnv, q_table: np.array, number_of_episodes:int = 10, number_of_steps: int = 50) -> bool:\n",
    "  # Please write your answer to Question 3B part ii))\n",
    "    rewards = []\n",
    "\n",
    "    for episode in range(number_of_episodes):\n",
    "        state = env.reset()[0]\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        #print(\"****************************************************\")\n",
    "        #print(\"EPISODE \", episode)\n",
    "\n",
    "        for step in range(number_of_steps):\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            # env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(q_table[state,:])\n",
    "\n",
    "            new_state, reward, transition, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "    print (\"Score over time: \" +  str(sum(rewards)/number_of_episodes))\n",
    "    return True\n",
    "\n",
    "q_run(TaxiEnv, q_table, 10,50) #based on Q table we learned\n",
    "q_table = np.zeros((obs_dim,act_dim)) #empty the Q table\n",
    "q_run(TaxiEnv, q_table, 10,50) #for random running?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC-qaSXky0yp"
   },
   "source": [
    "**Question 3C: State-of-the-art Reinforcement Learning \\\\\n",
    "Using the Taxi-v3 [environment](https://gym.openai.com/envs/Taxi-v3/) given below, please answer the following questions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWosM0Zpy4IN"
   },
   "source": [
    "**i) Using any reinforcement learning model of your choice, implement two functions:**  \\\\\n",
    "*   function that trains the reinforcement learning model of your choice\n",
    "*   function that runs 10 number of episodes with the action sampled from the trained network from the function above\n",
    "\n",
    "**With reference to the paper that you have decided to choose, explain how your code works in words [12 marks]** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n76nXbEZy7d4"
   },
   "outputs": [],
   "source": [
    "  # Please write your answer to Question 3C part i) here\n",
    "#Monte Carloì“¸ ê³„íš ì ì–´ë„ ë°°ì› ëŠ”ã„´ë°.... ê¸°ì–µì€ ì•ˆë‚˜ì§€ë§Œ^^....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv6RErrHy8u-"
   },
   "source": [
    "(Your answer to Question 3C part i))\n",
    "\n",
    "\n",
    "> Explanation of my code ... \\\\"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Akros Coding Test.ipynb",
   "provenance": [
    {
     "file_id": "16NQdfZcd7tRapZJ-XeQnGeRdWDpDyxqL",
     "timestamp": 1646965546708
    },
    {
     "file_id": "1DTj4VDkZSkvE6Ap3lTpcnM8f5XTKD0Od",
     "timestamp": 1646771515333
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
